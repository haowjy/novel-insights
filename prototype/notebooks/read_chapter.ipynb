{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "lib_path = Path('../../novelinsights/backend')\n",
    "sys.path.append(str(lib_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import anthropic\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(lib_path / '.env')\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n",
    "\n",
    "from novelinsights.services.ai.llmclient import AnthropicClient, GoogleGeminiClient\n",
    "\n",
    "G_CLIENT = GoogleGeminiClient(genai.Client(api_key=GEMINI_API_KEY))\n",
    "A_CLIENT = AnthropicClient(anthropic.Anthropic(api_key=ANTHROPIC_API_KEY))\n",
    "\n",
    "USE_CACHED_RESPONSES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "from typing import NamedTuple\n",
    "\n",
    "with open('../../novelinsights/backend/tests/resources/pokemon_amber/_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "    STORY_TITLE = metadata['story_title']\n",
    "    GENRES = metadata['genres']\n",
    "    ADDITIONAL_TAGS = metadata['additional_tags']\n",
    "    STORY_DESCRIPTION = metadata['story_description']\n",
    "\n",
    "\n",
    "class Chapter(NamedTuple):\n",
    "    chapter_title: str\n",
    "    chapter_content: str\n",
    "    chapter_number: int\n",
    "\n",
    "CHAPTERS = []\n",
    "\n",
    "num_chapters = 12\n",
    "\n",
    "for i in range(1, num_chapters + 1):\n",
    "    with open(f'../../novelinsights/backend/tests/resources/pokemon_amber/chapter{i}.json', 'r') as f:\n",
    "        chapter = json.load(f)\n",
    "        CHAPTER_TITLE = chapter['chapter_title']\n",
    "        CHAPTER_CONTENT = chapter['chapter_content']\n",
    "        CHAPTERS.append(Chapter(CHAPTER_TITLE, CHAPTER_CONTENT, i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelinsights.services.ai.llmclient import LLMResponse\n",
    "from novelinsights.services.ai.prompts.narrative.chapterbychapter.summarize import SummarizeChapterTemplate, SummarizeChapterPrompt\n",
    "\n",
    "summarize_prompt_template = SummarizeChapterTemplate(\n",
    "    story_title=STORY_TITLE,\n",
    "    genres=GENRES,\n",
    "    additional_tags=ADDITIONAL_TAGS,\n",
    "    story_description=STORY_DESCRIPTION,\n",
    "    chapter_title=CHAPTERS[0].chapter_title,\n",
    "    chapter_content=CHAPTERS[0].chapter_content,\n",
    "    structured_output_schema=None\n",
    ")\n",
    "summarize_prompt = SummarizeChapterPrompt(prompt_template=summarize_prompt_template)\n",
    "\n",
    "summarize_response: LLMResponse = None # type: ignore\n",
    "\n",
    "if USE_CACHED_RESPONSES:\n",
    "    if os.path.exists('../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/summarize.json'):\n",
    "        with open('../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/summarize.json', 'r') as f:\n",
    "            json_dict = json.load(f)\n",
    "            summarize_response = LLMResponse(response=json_dict.get(\"response\"), usage_metadata=json_dict.get(\"usage_metadata\"))\n",
    "\n",
    "if not summarize_response:\n",
    "    summarize_response = summarize_prompt.generate(client=A_CLIENT)\n",
    "\n",
    "    with open('../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/summarize.json', 'w') as f:\n",
    "        json.dump({\n",
    "            \"response\": summarize_response.get(\"response\"),\n",
    "            \"usage_metadata\": summarize_response.get(\"usage_metadata\"),\n",
    "            \"model_config\": asdict(summarize_prompt.model_config),\n",
    "        }, f, indent=2)\n",
    "\n",
    "# print(summarize_prompt.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelinsights.services.ai.prompts import FindEntitiesTemplate, FindEntitiesPrompt\n",
    "from novelinsights.schemas import FindEntitiesOutputSchema\n",
    "\n",
    "find_entities_template = FindEntitiesTemplate(\n",
    "    story_title=STORY_TITLE,\n",
    "    genres=GENRES,\n",
    "    additional_tags=ADDITIONAL_TAGS,\n",
    "    story_description=STORY_DESCRIPTION,\n",
    "    chapter_title=CHAPTERS[0].chapter_title,\n",
    "    chapter_content=CHAPTERS[0].chapter_content,\n",
    "    structured_output_schema=FindEntitiesOutputSchema\n",
    ")\n",
    "\n",
    "\n",
    "find_entities_prompt = FindEntitiesPrompt(prompt_template=find_entities_template)\n",
    "\n",
    "find_entities_response: LLMResponse = None # type: ignore\n",
    "\n",
    "if USE_CACHED_RESPONSES:\n",
    "    if os.path.exists('../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/find_entities.json'):\n",
    "        with open('../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/find_entities.json', 'r') as f:\n",
    "            json_dict = json.load(f)\n",
    "            validated_response = FindEntitiesOutputSchema.model_validate(json_dict.get(\"response\"))\n",
    "            find_entities_response = LLMResponse(response=validated_response, usage_metadata=json_dict.get(\"usage_metadata\"))\n",
    "\n",
    "if not find_entities_response:\n",
    "    find_entities_response = find_entities_prompt.generate_structured(client=G_CLIENT)\n",
    "\n",
    "    with open('../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/find_entities.json', 'w') as f:\n",
    "        json.dump({\n",
    "            \"response\": find_entities_response.get(\"response\").model_dump(mode=\"json\"),\n",
    "            \"usage_metadata\": find_entities_response.get(\"usage_metadata\"),\n",
    "            \"model_config\": asdict(find_entities_prompt.model_config),\n",
    "        }, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['character: AlexaTheGreat/Amber - central (related: Dr. Fuji, Mewtwo, Amber (clone))', 'character: Dr. Fuji - major (related: AlexaTheGreat/Amber, Mewtwo, Amber (clone), Pokemon Mansion)', 'character: Mewtwo - major (related: Dr. Fuji, AlexaTheGreat/Amber, Pokemon Mansion)', 'location: Pokemon Mansion - major (related: Dr. Fuji, Mewtwo, AlexaTheGreat/Amber)', 'character: Amber (clone) - major (related: Dr. Fuji, AlexaTheGreat/Amber, Mewtwo)']\n"
     ]
    }
   ],
   "source": [
    "# print(entities.keys())\n",
    "\n",
    "from novelinsights.schemas.prompt_responses.narrative.chapterbychapter.find_entities import FoundEntity\n",
    "from novelinsights.types.knowledge import EntitySignificanceLevel\n",
    "\n",
    "# I want to be able to iterate over the entities, skip the ones that are not significant, and in chunks of 5 so the output context window is not exceeded\n",
    "class KeyEntities:\n",
    "    \n",
    "    def __init__(self, entities: list[FoundEntity]):\n",
    "        self.entities = entities\n",
    "        entities_by_identifier = {entity.identifier: entity for entity in entities}\n",
    "        \n",
    "        self.related_entities_by_identifier = {} # entity id -> list of related entities\n",
    "        for entity in entities:\n",
    "            for related_entity_id in entity.related_entities:\n",
    "                if related_entity_id in entities_by_identifier:\n",
    "                    self.related_entities_by_identifier.setdefault(entity.identifier, []).append(entities_by_identifier.get(related_entity_id))\n",
    "                    \n",
    "    def get_sig_related_entities_for_upsert(self, entity_id: str, min_sig_level: EntitySignificanceLevel = EntitySignificanceLevel.SUPPORTING) -> list[str]:\n",
    "        return [entity.identifier for entity in self.related_entities_by_identifier.get(entity_id, []) if entity.significance_level >= min_sig_level]\n",
    "    \n",
    "    def yield_for_upsert(self, min_sig_level: EntitySignificanceLevel = EntitySignificanceLevel.SUPPORTING, chunk_size: int = 5):\n",
    "        significant_entities = []\n",
    "        for entity in self.entities:\n",
    "            if entity.significance_level >= min_sig_level:\n",
    "                significant_entities.append(entity.to_upsert_str(sig_related_entities=self.get_sig_related_entities_for_upsert(entity.identifier, min_sig_level)))\n",
    "            if len(significant_entities) == chunk_size:\n",
    "                yield significant_entities\n",
    "                significant_entities = []\n",
    "                \n",
    "        if significant_entities:\n",
    "            yield significant_entities\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"KeyEntities(entities={self.entities})\"\n",
    "    \n",
    "key_entities = KeyEntities(find_entities_response.get(\"response\").entities)\n",
    "\n",
    "for i, upsert_chunk in enumerate(key_entities.yield_for_upsert(min_sig_level=EntitySignificanceLevel.SUPPORTING, chunk_size=5)):   \n",
    "    print(upsert_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelinsights.schemas.prompt_responses.narrative.chapterbychapter.upsert_entities import UpsertEntitiesOutputSchema\n",
    "from novelinsights.services.ai.prompts.narrative.chapterbychapter.upsert_entities import UpsertEntitiesTemplate, UpsertEntitiesPrompt\n",
    "\n",
    "upsert_entities_template = UpsertEntitiesTemplate(\n",
    "        story_title=STORY_TITLE,\n",
    "        genres=GENRES,\n",
    "        additional_tags=ADDITIONAL_TAGS,\n",
    "        story_description=STORY_DESCRIPTION,\n",
    "        chapter_title=CHAPTERS[0].chapter_title,\n",
    "        chapter_content=CHAPTERS[0].chapter_content,\n",
    "        new_entities=[],\n",
    "        structured_output_schema=UpsertEntitiesOutputSchema\n",
    "    )\n",
    "upsert_entities_prompt = UpsertEntitiesPrompt(prompt_template=upsert_entities_template)\n",
    "\n",
    "upsert_entities_response_list = []\n",
    "\n",
    "for i, upsert_chunk in enumerate(key_entities.yield_for_upsert(min_sig_level=EntitySignificanceLevel.SUPPORTING, chunk_size=5)):   \n",
    "    upsert_entities_prompt.update_prompt_template(new_entities=upsert_chunk)\n",
    "    \n",
    "    upsert_entities_response: LLMResponse = None # type: ignore\n",
    "    \n",
    "    if USE_CACHED_RESPONSES:\n",
    "        if os.path.exists(f'../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/upsert_entities{i+1}.json'):\n",
    "            with open(f'../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/upsert_entities{i+1}.json', 'r') as f:\n",
    "                json_dict = json.load(f)\n",
    "                validated_response = UpsertEntitiesOutputSchema.model_validate(json_dict.get(\"response\"))\n",
    "                upsert_entities_response = LLMResponse(response=validated_response, usage_metadata=json_dict.get(\"usage_metadata\"))\n",
    "\n",
    "    if not upsert_entities_response:\n",
    "        upsert_entities_response = upsert_entities_prompt.generate_structured(client=G_CLIENT)\n",
    "\n",
    "        with open(f'../../novelinsights/backend/tests/resources/pokemon_amber/chapter1_out/upsert_entities{i+1}.json', 'w') as f:\n",
    "            json.dump({\n",
    "                \"response\": upsert_entities_response.get(\"response\").model_dump(mode=\"json\"),\n",
    "                \"usage_metadata\": upsert_entities_response.get(\"usage_metadata\"),\n",
    "                \"model_config\": asdict(upsert_entities_prompt.model_config),\n",
    "            }, f, indent=2)\n",
    "    \n",
    "    upsert_entities_response_list.append(upsert_entities_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
